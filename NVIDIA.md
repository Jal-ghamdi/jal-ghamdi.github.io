# I Passed Two NVIDIA Generative AI Certifications

- âœ… **NVIDIA-Certified Associate: Generative AI â€“ Large Language Models (LLMs)**  
- âœ… **NVIDIA-Certified Associate: Generative AI â€“ Multimodal**


---

## My Learning Journey

To prepare, I took this Coursera specialization:  
ğŸ”— [NVIDIA Exam Prep: Generative AI LLMs Associate]([https://www.coursera.org/specializations/exam-prep-nca-genl-nvidia-certified-generative-ai-llms-associate](https://www.coursera.org/specializations/exam-prep-nca-genl-nvidia-certified-generative-ai-llms-associate))

This course is good â€” especially if you want to **build a general understanding** of the topics before diving into more technical material. It walks through core topics like Transformers, fusion techniques, model evaluation metrics, and more.

> ğŸ’¡ **Important tip**: The **suggested readings in the study guide are _very_ important**. Theyâ€™re not just extra â€” some of the questions are actually drawn from the concepts explained in those readings. Donâ€™t skip them!

---

## Some Topics and Sample Questions I Saw

Without revealing anything confidential, here are the types of questions and concepts I was tested on:

### ğŸ”„ Overfitting and Underfitting

- **Whatâ€™s the most common sign that a model is overfitting?**  
  âœ… It performs well on training data but poorly on test data

- **Is mode collapse in GANs more like overfitting or underfitting?**  

---

### ğŸ§  CLIP and Diffusion

- CLIP provides shared embeddings and uses contrastive learning  
- CLIP helps in diffusion models, especially in guiding text-to-image generation  
- U-Net architecture in diffusion: encoder-decoder + skip connections

---

### ğŸ”„ Fusion Techniques

Understand and distinguish:

- **Early fusion** (combine data at input level)  
- **Late fusion** (combine model outputs)  
- **Data fusion** (general integration across modalities or sources)

---

### ğŸ“Š Data Visualization

- **Histogram** = continuous variables  
- **Bar chart** = categorical variables  
- Why visualize before handling missing values?  
  âœ… To detect patterns or anomalies  
- First step in handling missing values?  
  âœ… Analyze the pattern of missingness

---

### ğŸ“‹ ML Workflow Steps

Be able to order the following:

1. Data Collection  
2. Data Exploration  
3. Data Preprocessing  
4. Modeling  
5. Evaluation

---

### âš™ï¸ System Bottlenecks

**Whatâ€™s the best solution if CPU â†”ï¸ GPU throughput is the training bottleneck?**

A. Use a bigger batch size  
B. Increase CPU frequency  
**C. Increase CPU core count** âœ…  
D. Use FP64 precision

---

### âš ï¸ Bias in AI

**You're developing a face recognition model. What is the most likely type of bias that your model might suffer from?**

A. Temporal bias  
B. Measurement bias  
**C. Racial bias** âœ…  
D. Confirmation bias

---

### ğŸ§ª Evaluation Metrics

- **ASR (Speech)**: WER and CER  
- **Image Generation**: FID  
- **RAG (Retrieval-Augmented Generation)**: BLEU (precison) or ROUGE (Recall), Perplexity 

---

## ğŸ§° Other Concepts You Should Know

- CLIP, GAN, U-Net  
- Transformer: self-attention + positional encoding  
- Modality types: text, image, audio, etc.  
- Certified AI practices  
- Transfer learning  
- Mixed precision training  
- Pruning & quantization  
- A/B testing

---

## Final Thoughts

These certifications were a great way to deepen my practical knowledge in both LLMs and multimodal AI. They aren't overly difficult, but they do require **solid preparation**, especially in understanding the underlying concepts rather than just memorizing facts.

If you're thinking of taking them, my advice:
  
- âœ… Donâ€™t skip the **suggested readings**  
- âœ… Review key concepts like CLIP, U-Net, Transformers, fusion types, and evaluation metrics  
- âœ… And most importantly â€” enjoy the learning process!

